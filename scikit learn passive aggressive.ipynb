{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive-Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to implement a Passive-Aggressive classifier on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear daniel greenfield shillman ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy us secretary s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc tried...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matter primary day new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  label\n",
       "0  smell hillary fear daniel greenfield shillman ...      0\n",
       "1  watch exact moment paul ryan committed politic...      0\n",
       "2  kerry go paris gesture sympathy us secretary s...      1\n",
       "3  bernie supporter twitter erupt anger dnc tried...      0\n",
       "4  battle new york primary matter primary day new...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the code used to preprocess our dataset. \n",
    "# Each step is explained in detail in the 'Data Pre-processing' notebook.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('news/news.csv')\n",
    "df['news'] = df['title'] + ' ' + df['text']\n",
    "convert_to_binary = {'REAL':1,'FAKE':0}\n",
    "df['label'] = df['label'].map(convert_to_binary)\n",
    "df = df.drop([df.columns[0],df.columns[1],df.columns[2]],axis=1)\n",
    "df = df.reindex(columns=['news','label'])\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    filtered_article = ''\n",
    "    article = row['news']\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    df.loc[index, 'news'] = filtered_article\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x80967 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1762247 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorization\n",
    "df_input = df['news']\n",
    "df_output = df['label']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(df_input)\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "label_column = df.loc[:,'label']\n",
    "labels = label_column.values\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the Passive-Aggressive classifier from sikit learn\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Passive-aggressive classifier we need to split our dataset into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf_idf_matrix\n",
    "y = df_output.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Defining our model with a regularisation parameter\n",
    "model = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit our model to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Predictions\n",
    "y_predict = model.predict(x_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will measure our Passive-Aggressive model's performance with it fit to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352972119936875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %0.3f\" % (accuracy_score(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this passive-aggressive model has an accuracy of 93.4% which is good.\n",
    "\n",
    "We will now see how this model performs with a different train-test split ratio of 75:25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299242424242424"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.934\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %0.3f\" % (accuracy_score(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the accuracy of this model is 93.2% which is surprisingly slightly less accurate than a train-test split of 70:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.90625,\n",
       " 0.9291338582677166,\n",
       " 0.9528795811518325,\n",
       " 0.9488188976377953,\n",
       " 0.9369085173501577,\n",
       " 0.9343832020997376,\n",
       " 0.9301801801801802,\n",
       " 0.9349112426035503,\n",
       " 0.9316987740805605,\n",
       " 0.9290220820189274,\n",
       " 0.9325681492109039,\n",
       " 0.9316688567674113,\n",
       " 0.9344660194174758,\n",
       " 0.9402480270574972,\n",
       " 0.935856992639327,\n",
       " 0.9388560157790927,\n",
       " 0.9350046425255338,\n",
       " 0.9360210341805434,\n",
       " 0.9352159468438538,\n",
       " 0.9376479873717443,\n",
       " 0.9346356123215628,\n",
       " 0.9325681492109039,\n",
       " 0.9362139917695473,\n",
       " 0.9355687047994741,\n",
       " 0.9343434343434344,\n",
       " 0.9350728155339806,\n",
       " 0.9339567504383401,\n",
       " 0.9334836527621195,\n",
       " 0.9336235038084875,\n",
       " 0.932140978432404,\n",
       " 0.9368635437881874,\n",
       " 0.9378698224852071,\n",
       " 0.937350549976088,\n",
       " 0.9350046425255338,\n",
       " 0.933273219116321,\n",
       " 0.9333625602805787,\n",
       " 0.9304607508532423,\n",
       " 0.9302325581395349,\n",
       " 0.9307972480777014,\n",
       " 0.9297553275453828,\n",
       " 0.9257120862201693,\n",
       " 0.9259676813228109,\n",
       " 0.9262385321100918,\n",
       " 0.922883787661406,\n",
       " 0.9224833391792353,\n",
       " 0.9238421955403088,\n",
       " 0.9244459368703828,\n",
       " 0.9273265373232489,\n",
       " 0.9252818035426731]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sizes = np.arange(0.01,0.5,0.01)\n",
    "accuracys = []\n",
    "for i in test_sizes:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=i, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    accuracys.append(accuracy)\n",
    "    \n",
    "accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Passive-Aggressive Classifier Accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(test_sizes, accuracys)\n",
    "plt.xlabel('Test Size')\n",
    "plt.ylabel('Passive-Aggressive Classifier Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sizes[np.argmax(accuracys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our Passive-Aggressive classifier model has greatest accuracy with a very small test size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the performance of our model we can use a confusion matrix. This compares the predicted class with the actual class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1459,  102],\n",
       "       [ 130, 1414]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_test, model.predict(x_test))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of the model on fake news articles: 0.934657270980141\n",
      "Success rate of the model on real news articles: 0.9158031088082902\n"
     ]
    }
   ],
   "source": [
    "print('Success rate of the model on fake news articles: ' + str(confusion[0][0]/(confusion[0][0] + confusion[0][1])))\n",
    "print('Success rate of the model on real news articles: ' + str(confusion[1][1]/(confusion[1][0] + confusion[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the passive-agresive model is more accurate at classifying fake news articles compared to real news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built a Passive-Aggressive classifier model, we want to see how this model performs on unseen data. We will now preprocess two articles, one real and one fake, into vector form so we can test our model on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "    \n",
    "\n",
    "def article_preprocessor (article):\n",
    "    filtered_article = ''\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    return filtered_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passive_aggressive_classifier (list_of_articles):\n",
    "    \n",
    "    #To preprocess these articles\n",
    "    articles_pp = [article_preprocessor(article) for article in list_of_articles]\n",
    "    new_input = df_input.append(pd.Series(articles_pp))\n",
    "    tf_idf_matrix = vectorizer.fit_transform(new_input)\n",
    "    orig_data_matrix = tf_idf_matrix[:len(df_input)]\n",
    "    new_data_matrix = tf_idf_matrix[len(df_input):]\n",
    "    \n",
    "    #Performing the Passive-Aggressive classifier on the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(orig_data_matrix, df_output, random_state=42)\n",
    "    model = PassiveAggressiveClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test,y_test)\n",
    "    print('The Passive-Aggressive classifier model accuracy: ' +str(accuracy))\n",
    "    \n",
    "    prediction = model.predict(new_data_matrix)\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top news story on the BBC\n",
    "bbc_news_article = '''The furlough scheme will be extended until the end of September by the chancellor in the Budget later.\n",
    "Rishi Sunak said the scheme - which pays 80% of employees' wages for the hours they cannot work in the pandemic - would help millions through \"the challenging months ahead\".\n",
    "Some 600,000 more self-employed people will also be eligible for government help as access to grants is widened.\n",
    "But Labour said the support schemes should have been extended \"months ago\".\n",
    "Mr Sunak will outline a three-point plan to support people through the coming months, rebuild the economy and \"fix\" the public finances in the wake of the pandemic when he delivers his statement to the Commons at about 12:30 GMT.\n",
    "But he has warned of tough economic times ahead and there are reports that he plans to raise some taxes.'''\n",
    "\n",
    "# Here's a fake news article from the New York Mag\n",
    "fake_article = '''Twelve days out from judgment day in an election in which he continues to trail badly, President Trump continues to hammer home an issue that will surely resonate with that small slice of still-undecided voters: his supposedly unfair treatment at the hands of CBS’s Lesley Stahl. After two days of promising to release unedited footage of an as-yet-unaired 60 Minutes interview, during which he walked out prematurely because he was upset with Stahl’s line of questioning, the president finally followed through on Thursday. Throughout the interview, Stahl presses Trump on issues from health care (the president says he hopes the Supreme Court strikes down Obamacare, a politically toxic position) to his derogatory comments about Anthony Fauci (Trump claims he was misinterpreted) to his false claims that the Obama campaign spied on him. The tone is of an adversarial back-and-forth, well within normal journalistic bounds. Nevertheless, Trump continuously claims that Joe Biden hasn’t been given similar treatment by CBS and cuts the proceedings short.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Passive-Aggressive classifier model accuracy: 0.9311868686868687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [bbc_news_article,fake_article]\n",
    "passive_aggressive_classifier(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our Passive-Aggressive classifier has correctly classified both the real and the fake news article!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try and improve our model's performance using grid search. The Passive-Aggressive classifier does not have a learning rate, so we can see how changing the regularisation parameter would affect the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf_idf_matrix\n",
    "y = df_output.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PassiveAggressiveClassifier()\n",
    "#C is the regularisation parameter of our Passive-Aggressive model\n",
    "param_grid = {\"C\": [0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 1.0, 2.0],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.937\n"
     ]
    }
   ],
   "source": [
    "results = grid.fit(x_train, y_train)\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.906 with: {'C': 0.001}\n",
      ">0.916 with: {'C': 0.002}\n",
      ">0.935 with: {'C': 0.01}\n",
      ">0.937 with: {'C': 0.02}\n",
      ">0.937 with: {'C': 0.1}\n",
      ">0.936 with: {'C': 0.2}\n",
      ">0.935 with: {'C': 1.0}\n",
      ">0.936 with: {'C': 2.0}\n"
     ]
    }
   ],
   "source": [
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can see that the accuracy of our Passive-Aggressive classifier model varies when we change the regularisation parameter, and our model performs best with a regularisation parameter of 0.02 with an accuracy of 93.8%.\n",
    "\n",
    "Now to test whether varying the proportion of training data set aside as validation set will affect the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.936 with: {'validation_fraction': 0.001}\n",
      ">0.936 with: {'validation_fraction': 0.002}\n",
      ">0.936 with: {'validation_fraction': 0.01}\n",
      ">0.937 with: {'validation_fraction': 0.02}\n",
      ">0.937 with: {'validation_fraction': 0.1}\n",
      ">0.936 with: {'validation_fraction': 0.2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"validation_fraction\": [0.001, 0.002, 0.01, 0.02, 0.1, 0.2],}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "results = grid.fit(x_train, y_train)\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the accuracy doesnt change too much with different validation fractions, but has greatest accuracy of 93.7% with a validation fraction of 0.02.\n",
    "\n",
    "We can also test whether the random state of our model will affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.936 with: {'random_state': 0}\n",
      ">0.935 with: {'random_state': 1}\n",
      ">0.937 with: {'random_state': 5}\n",
      ">0.937 with: {'random_state': 25}\n",
      ">0.937 with: {'random_state': 42}\n",
      ">0.936 with: {'random_state': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"random_state\": [0, 1, 5, 25, 42, 50],}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "results = grid.fit(x_train, y_train)\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our model has a greater accuracy with a random state of 42 compared to the default random state of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
