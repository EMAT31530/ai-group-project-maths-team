{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be attempting to build a classification model to determine whether a particular article is considered to be \"fake news\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake News\n",
    "\n",
    "The term \"fake news\" was promulgated by Donald Trump in the lead up to his 2016 US election win and has since become the most dominating narrative in politics and media.\n",
    "\n",
    "**Fake news** is any false or misleaing information represented as news. It is commonly spread on the internet through social media platforms such as Twitter and Facebook, and is usually created to influence political views or as a joke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "### Training data  \n",
    "First we shall read in our training data set, which consists of a variety of news headlines and texts aligned with a label stating whether the article is fake news or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8  Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9  Iranian negotiators reportedly have made a las...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('news.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the size of our training data set.\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  title   text  label\n",
      "0          False  False  False  False\n",
      "1          False  False  False  False\n",
      "2          False  False  False  False\n",
      "3          False  False  False  False\n",
      "4          False  False  False  False\n",
      "...          ...    ...    ...    ...\n",
      "6330       False  False  False  False\n",
      "6331       False  False  False  False\n",
      "6332       False  False  False  False\n",
      "6333       False  False  False  False\n",
      "6334       False  False  False  False\n",
      "\n",
      "[6335 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Here we shall check whether our data set contains any null values.\n",
    "check_nan_in_df = df.isnull()\n",
    "print(check_nan_in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that the data set contains no null/missing values.\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing our data\n",
    "\n",
    "We now want to convert our training data set into a series of input-output pairs, in order to build our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                          total_text  \n",
       "0  You Can Smell Hillary’s Fear Daniel Greenfield...  \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "2  Kerry to go to Paris in gesture of sympathy U....  \n",
       "3  Bernie supporters on Twitter erupt in anger ag...  \n",
       "4  The Battle of New York: Why This Primary Matte...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's combine the title and text columns to create our input x\n",
    "df['total_text'] = df['title'] + ' ' + df['text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our inputs x within the column 'total_text' and the corrseponding outputs y in the 'label' column.  \n",
    "However, we would like to alter our data into a more interpretable form.\n",
    "\n",
    "First, let's convert our labels into binary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0   \n",
       "4  It's primary day in New York and front-runners...      1   \n",
       "\n",
       "                                          total_text  \n",
       "0  You Can Smell Hillary’s Fear Daniel Greenfield...  \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "2  Kerry to go to Paris in gesture of sympathy U....  \n",
       "3  Bernie supporters on Twitter erupt in anger ag...  \n",
       "4  The Battle of New York: Why This Primary Matte...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set Real to 1 and Fake to 0.\n",
    "as_binary = {'REAL':1,'FAKE':0}\n",
    "df['label'] = df['label'].map(as_binary)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to clean up our text, making it more analysable. We will use the natural language toolkit package to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxkirwan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/maxkirwan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/maxkirwan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attempt to remove stopwords from an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = \"This is an example sentence. Hello World! I wonder if this won't work.\"\n",
    "word_tokens = word_tokenize(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'example',\n",
       " 'sentence',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'World',\n",
       " '!',\n",
       " 'I',\n",
       " 'wonder',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'work',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that worked. Now let's do the same for each row of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "      <td>you can smell hillary ’ fear daniel greenfiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch the exact moment paul ryan committed po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>kerry go paris gesture sympathy u.s. secretar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc : 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "      <td>the battle new york : why this primary matter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0   \n",
       "4  It's primary day in New York and front-runners...      1   \n",
       "\n",
       "                                          total_text  \n",
       "0   you can smell hillary ’ fear daniel greenfiel...  \n",
       "1   watch the exact moment paul ryan committed po...  \n",
       "2   kerry go paris gesture sympathy u.s. secretar...  \n",
       "3   bernie supporter twitter erupt anger dnc : 'w...  \n",
       "4   the battle new york : why this primary matter...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = row['total_text']\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Stopwords removal\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # Lemmatization\n",
    "    for words in words:\n",
    "        filter_sentence = filter_sentence  + ' ' + str(lemmatizer.lemmatize(words)).lower()\n",
    "    \n",
    "    df.loc[index, 'total_text'] = filter_sentence\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our dataset as a list of inputs and their corrseponding output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df['total_text']\n",
    "df_output = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "We need to map sentences from our corpus to a corresponding vector of real numbers in order to be able to find similarities between sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 63465)\t0.026753191864679532\n",
      "  (0, 63456)\t0.029127230661968165\n",
      "  (0, 63329)\t0.017574068463097534\n",
      "  (0, 63043)\t0.0355978832627074\n",
      "  (0, 63032)\t0.023161109883121193\n",
      "  (0, 62994)\t0.035107806500506475\n",
      "  (0, 62951)\t0.02642747375066598\n",
      "  (0, 62946)\t0.008338732795996964\n",
      "  (0, 62852)\t0.015361736862855021\n",
      "  (0, 62768)\t0.01415977077238262\n",
      "  (0, 62674)\t0.027209931227428756\n",
      "  (0, 62673)\t0.0161121219800601\n",
      "  (0, 62610)\t0.037523294771871676\n",
      "  (0, 62551)\t0.04100357361375188\n",
      "  (0, 62421)\t0.03343829289162133\n",
      "  (0, 62342)\t0.034324696573588824\n",
      "  (0, 62317)\t0.01764470347226561\n",
      "  (0, 62207)\t0.013343695286012296\n",
      "  (0, 62193)\t0.013915650398710271\n",
      "  (0, 62170)\t0.05938126091694468\n",
      "  (0, 62045)\t0.011083466210046834\n",
      "  (0, 62004)\t0.025968437181222048\n",
      "  (0, 61909)\t0.04131271254666581\n",
      "  (0, 61827)\t0.031496376386581454\n",
      "  (0, 61766)\t0.022598295988027487\n",
      "  :\t:\n",
      "  (6334, 5684)\t0.034466651267223564\n",
      "  (6334, 5674)\t0.09538401268982359\n",
      "  (6334, 5670)\t0.11078944910604521\n",
      "  (6334, 5576)\t0.018711107807023963\n",
      "  (6334, 5133)\t0.017235874884104257\n",
      "  (6334, 5051)\t0.03228491047387169\n",
      "  (6334, 5007)\t0.03239442054506066\n",
      "  (6334, 4808)\t0.05086298859978334\n",
      "  (6334, 4751)\t0.03815167959432204\n",
      "  (6334, 4726)\t0.025361486233993577\n",
      "  (6334, 4723)\t0.02604790362974165\n",
      "  (6334, 4719)\t0.05381799369606106\n",
      "  (6334, 4609)\t0.03372284200963444\n",
      "  (6334, 4285)\t0.030496217040314497\n",
      "  (6334, 4206)\t0.01287124023894657\n",
      "  (6334, 4196)\t0.037235203486565484\n",
      "  (6334, 3832)\t0.02291511967122295\n",
      "  (6334, 3711)\t0.032248771853058064\n",
      "  (6334, 3296)\t0.028168216443478528\n",
      "  (6334, 3001)\t0.031965973873955104\n",
      "  (6334, 2590)\t0.01628822560136851\n",
      "  (6334, 1624)\t0.05357845837622197\n",
      "  (6334, 948)\t0.02527835975684923\n",
      "  (6334, 929)\t0.027048343035907516\n",
      "  (6334, 783)\t0.014410824663693096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(df_input)\n",
    "freq_term_matrix = count_vectorizer.transform(df_input)\n",
    "\n",
    "tfidf = TfidfTransformer(norm = \"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)\n",
    "\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x64374 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1844605 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
