{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import Model\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    X_train = numpy.load('X_train.npy')\n",
    "    Y_train = numpy.load('Y_train.npy')\n",
    "    X_val = numpy.load('X_val.npy')\n",
    "    Y_val = numpy.load('Y_val.npy')\n",
    "    X_test = numpy.load('X_test.npy')\n",
    "    Y_test = numpy.load('Y_test.npy')\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(X_train, X_val, X_test):\n",
    "    \n",
    "# input dimension?\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([32, 64, 128,256,512,1024,2048,4096])}}, input_dim = 80967, activation='relu')) \n",
    "    model.add(Dense({{choice([32, 64, 128,256,512,1024,2048])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([16, 32, 64,128,256,512,1024])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([8, 16, 32,64,128,256,512])}}, activation='relu', name='encoded'))\n",
    "    model.add(Dense({{choice([16, 32, 64,128,256,512,1024])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([32, 64, 128,256,512,1024,2048])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([32, 64, 128,256,512,1024,2048,4096])}}, activation='relu'))\n",
    "    model.add(Dense(80967))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=SGD(learning_rate={{uniform(0, 1)}}), metrics=['mse'])\n",
    "\n",
    "    history = model.fit(X_train, X_train, epochs = 1,\n",
    "              batch_size={{choice([2000, 2750, 3300])}},\n",
    "              verbose=1,\n",
    "              validation_data=(X_val, X_val))\n",
    "    score, mse = model.evaluate(X_test, X_test, verbose=1)\n",
    "    \n",
    "    plt.plot(history.history['loss']) #Â how make sure plots best model only?\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    \n",
    "    return {'loss': mse, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [32, 64, 128,256,512,1024,2048,4096]),\n",
      "        'Dense_1': hp.choice('Dense_1', [32, 64, 128,256,512,1024,2048]),\n",
      "        'Dense_2': hp.choice('Dense_2', [16, 32, 64,128,256,512,1024]),\n",
      "        'Dense_3': hp.choice('Dense_3', [8, 16, 32,64,128,256,512]),\n",
      "        'Dense_4': hp.choice('Dense_4', [16, 32, 64,128,256,512,1024]),\n",
      "        'Dense_5': hp.choice('Dense_5', [32, 64, 128,256,512,1024,2048]),\n",
      "        'Dense_6': hp.choice('Dense_6', [32, 64, 128,256,512,1024,2048,4096]),\n",
      "        'learning_rate': hp.uniform('learning_rate', 0, 1),\n",
      "        'batch_size': hp.choice('batch_size', [2000, 2750, 3300]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: X_train = numpy.load('X_train.npy')\n",
      "  3: Y_train = numpy.load('Y_train.npy')\n",
      "  4: X_val = numpy.load('X_val.npy')\n",
      "  5: Y_val = numpy.load('Y_val.npy')\n",
      "  6: X_test = numpy.load('X_test.npy')\n",
      "  7: Y_test = numpy.load('Y_test.npy')\n",
      "  8: \n",
      "  9: \n",
      " 10: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = Sequential()\n",
      "   5:     model.add(Dense(space['Dense'], input_dim = 80967, activation='relu'))\n",
      "   6:     model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "   7:     model.add(Dense(space['Dense_2'], activation='relu'))\n",
      "   8:     model.add(Dense(space['Dense_3'], activation='relu', name='encoded'))\n",
      "   9:     model.add(Dense(space['Dense_4'], activation='relu'))\n",
      "  10:     model.add(Dense(space['Dense_5'], activation='relu'))\n",
      "  11:     model.add(Dense(space['Dense_6'], activation='relu'))\n",
      "  12:     model.add(Dense(80967))\n",
      "  13:     \n",
      "  14:     model.compile(loss='mse', optimizer=SGD(learning_rate=space['learning_rate']), metrics=['mse'])\n",
      "  15: \n",
      "  16:     history = model.fit(X_train, X_train, epochs = 3,\n",
      "  17:               batch_size=space['batch_size'],\n",
      "  18:               verbose=1,\n",
      "  19:               validation_data=(X_val, X_val))\n",
      "  20:     score, mse = model.evaluate(X_test, X_test, verbose=1)\n",
      "  21:     \n",
      "  22:     plt.plot(history.history['loss'])\n",
      "  23:     plt.xlabel('epochs')\n",
      "  24:     plt.ylabel('loss')\n",
      "  25:     \n",
      "  26:     return {'loss': mse, 'status': STATUS_OK, 'model': model}\n",
      "  27: \n",
      "Epoch 1/3                                            \n",
      "1/2 [==============>...............]                 \n",
      " - ETA: 2:19 - loss: 0.7750 - mse: 0.7750            \n",
      "                                                     \n",
      "2/2 [==============================]                 \n",
      " - ETA: 0s - loss: 0.7766 - mse: 0.7766              \n",
      "                                                     \n",
      "2/2 [==============================]                 \n",
      " - 1039s 899s/step - loss: 0.7771 - mse: 0.7771 - val_loss: 1.9797 - val_mse: 1.9797\n",
      "\n",
      "Epoch 2/3                                            \n",
      "1/2 [==============>...............]                 \n",
      " - ETA: 1:06 - loss: 0.7983 - mse: 0.7983            \n",
      "                                                     \n",
      "2/2 [==============================]                 \n",
      " - ETA: 0s - loss: 0.7882 - mse: 0.7882              \n",
      "                                                     \n",
      "2/2 [==============================]                 \n",
      " - 106s 39s/step - loss: 0.7849 - mse: 0.7849 - val_loss: 1.9797 - val_mse: 1.9797\n",
      "\n",
      "Epoch 3/3                                            \n",
      "1/2 [==============>...............]                 \n",
      " - ETA: 58s - loss: 0.7781 - mse: 0.7781             \n",
      "                                                    \n",
      "2/2 [==============================]                 \n",
      " - ETA: 0s - loss: 0.7782 - mse: 0.7782              \n",
      "                                                     \n",
      "2/2 [==============================]                 \n",
      " - 92s 34s/step - loss: 0.7782 - mse: 0.7782 - val_loss: 1.9797 - val_mse: 1.9797\n",
      "\n",
      " 1/40 [..............................]               \n",
      " - ETA: 1:47 - loss: 1.9040 - mse: 1.9040            \n",
      "                                                     \n",
      " 2/40 [>.............................]               \n",
      " - ETA: 9s - loss: 2.1153 - mse: 2.1153              \n",
      "                                                     \n",
      " 3/40 [=>............................]               \n",
      " - ETA: 10s - loss: 2.1770 - mse: 2.1770             \n",
      "                                                    \n",
      " 4/40 [==>...........................]               \n",
      " - ETA: 10s - loss: 3.2844 - mse: 3.2844             \n",
      "                                                    \n",
      " 5/40 [==>...........................]               \n",
      " - ETA: 9s - loss: 2.9747 - mse: 2.9747              \n",
      "                                                     \n",
      " 6/40 [===>..........................]               \n",
      " - ETA: 9s - loss: 2.6548 - mse: 2.6548              \n",
      "                                                     \n",
      " 7/40 [====>.........................]               \n",
      " - ETA: 8s - loss: 2.4554 - mse: 2.4554              \n",
      "                                                     \n",
      " 8/40 [=====>........................]               \n",
      " - ETA: 8s - loss: 2.6152 - mse: 2.6152              \n",
      "                                                     \n",
      " 9/40 [=====>........................]               \n",
      " - ETA: 7s - loss: 2.5497 - mse: 2.5497              \n",
      "                                                     \n",
      "10/40 [======>.......................]               \n",
      " - ETA: 7s - loss: 2.6016 - mse: 2.6016              \n",
      "                                                     \n",
      "11/40 [=======>......................]               \n",
      " - ETA: 6s - loss: 2.5424 - mse: 2.5424              \n",
      "                                                     \n",
      "12/40 [========>.....................]               \n",
      " - ETA: 6s - loss: 2.4480 - mse: 2.4480              \n",
      "                                                     \n",
      "13/40 [========>.....................]               \n",
      " - ETA: 6s - loss: 2.3517 - mse: 2.3517              \n",
      "                                                     \n",
      "14/40 [=========>....................]               \n",
      " - ETA: 6s - loss: 2.3078 - mse: 2.3078              \n",
      "                                                     \n",
      "15/40 [==========>...................]               \n",
      " - ETA: 5s - loss: 2.2743 - mse: 2.2743              \n",
      "                                                     \n",
      "16/40 [===========>..................]               \n",
      " - ETA: 5s - loss: 2.2399 - mse: 2.2399              \n",
      "                                                     \n",
      "17/40 [===========>..................]               \n",
      " - ETA: 5s - loss: 2.1944 - mse: 2.1944              \n",
      "                                                     \n",
      "18/40 [============>.................]               \n",
      " - ETA: 5s - loss: 2.1732 - mse: 2.1732              \n",
      "                                                     \n",
      "19/40 [=============>................]               \n",
      " - ETA: 4s - loss: 2.1628 - mse: 2.1628              \n",
      "                                                     \n",
      "20/40 [==============>...............]               \n",
      " - ETA: 4s - loss: 2.4799 - mse: 2.4799              \n",
      "                                                     \n",
      "21/40 [==============>...............]               \n",
      " - ETA: 4s - loss: 2.4348 - mse: 2.4348              \n",
      "                                                     \n",
      "22/40 [===============>..............]               \n",
      " - ETA: 4s - loss: 2.4007 - mse: 2.4007              \n",
      "                                                     \n",
      "23/40 [================>.............]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 3s - loss: 2.4085 - mse: 2.4085              \n",
      "                                                     \n",
      "24/40 [=================>............]               \n",
      " - ETA: 3s - loss: 2.3593 - mse: 2.3593              \n",
      "                                                     \n",
      "25/40 [=================>............]               \n",
      " - ETA: 3s - loss: 2.3283 - mse: 2.3283              \n",
      "                                                     \n",
      "26/40 [==================>...........]               \n",
      " - ETA: 3s - loss: 2.2946 - mse: 2.2946              \n",
      "                                                     \n",
      "27/40 [===================>..........]               \n",
      " - ETA: 2s - loss: 2.2966 - mse: 2.2966              \n",
      "                                                     \n",
      "28/40 [====================>.........]               \n",
      " - ETA: 2s - loss: 2.2655 - mse: 2.2655              \n",
      "                                                     \n",
      "29/40 [====================>.........]               \n",
      " - ETA: 2s - loss: 2.2650 - mse: 2.2650              \n",
      "                                                     \n",
      "30/40 [=====================>........]               \n",
      " - ETA: 2s - loss: 2.2871 - mse: 2.2871              \n",
      "                                                     \n",
      "31/40 [======================>.......]               \n",
      " - ETA: 1s - loss: 2.3336 - mse: 2.3336              \n",
      "                                                     \n",
      "32/40 [=======================>......]               \n",
      " - ETA: 1s - loss: 2.3012 - mse: 2.3012              \n",
      "                                                     \n",
      "33/40 [=======================>......]               \n",
      " - ETA: 1s - loss: 2.2822 - mse: 2.2822              \n",
      "                                                     \n",
      "34/40 [========================>.....]               \n",
      " - ETA: 1s - loss: 2.3022 - mse: 2.3022              \n",
      "                                                     \n",
      "35/40 [=========================>....]               \n",
      " - ETA: 1s - loss: 2.2956 - mse: 2.2956              \n",
      "                                                     \n",
      "36/40 [==========================>...]               \n",
      " - ETA: 0s - loss: 2.2610 - mse: 2.2610              \n",
      "                                                     \n",
      "37/40 [==========================>...]               \n",
      " - ETA: 0s - loss: 2.2480 - mse: 2.2480              \n",
      "                                                     \n",
      "38/40 [===========================>..]               \n",
      " - ETA: 0s - loss: 2.2230 - mse: 2.2230              \n",
      "                                                     \n",
      "39/40 [============================>.]               \n",
      " - ETA: 0s - loss: 2.3227 - mse: 2.3227              \n",
      "                                                     \n",
      "40/40 [==============================]               \n",
      " - ETA: 0s - loss: 2.3054 - mse: 2.3054              \n",
      "                                                     \n",
      "40/40 [==============================]               \n",
      " - 11s 217ms/step - loss: 2.3054 - mse: 2.3054       \n",
      "\n",
      "100%|ââââââââââ| 1/1 [21:25<00:00, 1285.94s/trial, best loss: 2.3054444789886475]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data()\n",
    "\n",
    "import numpy\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_run, best_model = optim.minimize(model=autoencoder,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=1,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Hyperas_Autoencoder')\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "40/40 [==============================] - 9s 183ms/step - loss: 2.3054 - mse: 2.3054\n",
      "[2.3054444789886475, 2.3054444789886475]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the Learning rate individually as required for the KNN file\n",
    "\n",
    "numpy.save('encoder_LR',best_run['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = best_model.get_layer('encoded').output\n",
    "encoder = Model(best_model.input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved encoder to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "encoder_json = encoder.to_json()\n",
    "with open(\"encoder.json\", \"w\") as json_file:\n",
    "    json_file.write(encoder_json)\n",
    "# serialize weights to HDF5\n",
    "encoder.save_weights(\"encoder.h5\")\n",
    "print(\"Saved encoder to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
