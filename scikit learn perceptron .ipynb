{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to implement the Perceptron Algorithm on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear daniel greenfield shillman ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy us secretary s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc tried...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matter primary day new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  label\n",
       "0  smell hillary fear daniel greenfield shillman ...      0\n",
       "1  watch exact moment paul ryan committed politic...      0\n",
       "2  kerry go paris gesture sympathy us secretary s...      1\n",
       "3  bernie supporter twitter erupt anger dnc tried...      0\n",
       "4  battle new york primary matter primary day new...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the code used to preprocess our dataset. \n",
    "# Each step is explained in detail in the 'Data Pre-processing' notebook.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('news/news.csv')\n",
    "df['news'] = df['title'] + ' ' + df['text']\n",
    "convert_to_binary = {'REAL':1,'FAKE':0}\n",
    "df['label'] = df['label'].map(convert_to_binary)\n",
    "df = df.drop([df.columns[0],df.columns[1],df.columns[2]],axis=1)\n",
    "df = df.reindex(columns=['news','label'])\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    filtered_article = ''\n",
    "    article = row['news']\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    df.loc[index, 'news'] = filtered_article\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x80967 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1762247 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorization\n",
    "df_input = df['news']\n",
    "df_output = df['label']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(df_input)\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "label_column = df.loc[:,'label']\n",
    "labels = label_column.values\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the Perceptron algorithm from scikit learn\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Perceptron algorithm we need to split our dataset into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf_idf_matrix\n",
    "y = df_output.values\n",
    "model = Perceptron()\n",
    "\n",
    "#We will use 'train_test_split' funcition to split our dataset into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will measure the Perceptron model's performance with it fit to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923198316675434"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementing our model with the test data\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.923\n"
     ]
    }
   ],
   "source": [
    "#Measuring the performance of our model\n",
    "print(\"accuracy: %0.3f\" % (accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the accuracy is 92.3% which is good.\n",
    "\n",
    "Now to test the accuracy of the model using a different training and test data size.\n",
    "We will split the training and test data with a 75:25 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "model.score(x_test, y_test)\n",
    "%time model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.930\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %0.3f\" % (accuracy_score(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the model has a better accuracy of 93% using a 75:25 ratio of train to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.921875,\n",
       " 0.937007874015748,\n",
       " 0.9476439790575916,\n",
       " 0.9212598425196851,\n",
       " 0.917981072555205,\n",
       " 0.9422572178477691,\n",
       " 0.9301801801801802,\n",
       " 0.9171597633136095,\n",
       " 0.9316987740805605,\n",
       " 0.919558359621451,\n",
       " 0.926829268292683,\n",
       " 0.9224704336399474,\n",
       " 0.9356796116504854,\n",
       " 0.9425028184892897,\n",
       " 0.92534174553102,\n",
       " 0.928007889546351,\n",
       " 0.9285051067780873,\n",
       " 0.9237510955302366,\n",
       " 0.9352159468438538,\n",
       " 0.9281767955801105,\n",
       " 0.9226145755071374,\n",
       " 0.9296987087517934,\n",
       " 0.9224965706447188,\n",
       " 0.9171597633136095,\n",
       " 0.9299242424242424,\n",
       " 0.9180825242718447,\n",
       " 0.9228521332554062,\n",
       " 0.9272829763246899,\n",
       " 0.9221980413492927,\n",
       " 0.923198316675434,\n",
       " 0.9307535641547862,\n",
       " 0.9235700197238659,\n",
       " 0.9258727881396461,\n",
       " 0.9275766016713092,\n",
       " 0.9251577998196574,\n",
       " 0.9254712845243315,\n",
       " 0.9168088737201365,\n",
       " 0.9156976744186046,\n",
       " 0.9194658033184946,\n",
       " 0.9194948697711128,\n",
       " 0.9122401847575058,\n",
       " 0.9086809470124013,\n",
       " 0.913394495412844,\n",
       " 0.9088952654232425,\n",
       " 0.9168712732374605,\n",
       " 0.9097770154373928,\n",
       " 0.9086635325721961,\n",
       " 0.9177902005919105,\n",
       " 0.9066022544283414]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sizes = np.arange(0.01,0.5,0.01)\n",
    "accuracys = []\n",
    "for i in test_sizes:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=i, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    accuracys.append(accuracy)\n",
    "    \n",
    "accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Perceptron Algorithm Accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(test_sizes, accuracys)\n",
    "plt.xlabel('Test Size')\n",
    "plt.ylabel('Perceptron Algorithm Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sizes[np.argmax(accuracys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our Perceptron Algorithm model has greatest accuracy with a very small test size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the performance of our model, we can use a confusion matrix. This compares the actual class with the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_test, model.predict(x_test))\n",
    "classification = metrics.classification_report(y_test,model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate of the model on fake news articles: 0.9051889814221653\n",
      "Success rate of the model on real news articles: 0.9080310880829016\n"
     ]
    }
   ],
   "source": [
    "print('Success rate of the model on fake news articles: ' + str(confusion[0][0]/(confusion[0][0] + confusion[0][1])))\n",
    "print('Success rate of the model on real news articles: ' + str(confusion[1][1]/(confusion[1][0] + confusion[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence this model is quite accurate when classifying news articles, and slightly more accurate at predicting real news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the relevant metrics other than accuracy, which are precision, recall and the harmonic average of precision and recall which is the f1-score. This gives us a better evaluation of the performance of our Perceptron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1413  148]\n",
      " [ 142 1402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1561\n",
      "           1       0.90      0.91      0.91      1544\n",
      "\n",
      "    accuracy                           0.91      3105\n",
      "   macro avg       0.91      0.91      0.91      3105\n",
      "weighted avg       0.91      0.91      0.91      3105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have high precision and recall with an F1 score of 0.91 for both real and fake articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built a Perceptron algorithm model, we want to see how this model performs on unseen data. We will now preprocess two articles, one real and one fake, into vector form so we can test our model on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "    \n",
    "\n",
    "def article_preprocessor (article):\n",
    "    filtered_article = ''\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    return filtered_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_classifier (list_of_articles):\n",
    "    \n",
    "    #To preprocess these articles\n",
    "    articles_pp = [article_preprocessor(article) for article in list_of_articles]\n",
    "    new_input = df_input.append(pd.Series(articles_pp))\n",
    "    tf_idf_matrix = vectorizer.fit_transform(new_input)\n",
    "    orig_data_matrix = tf_idf_matrix[:len(df_input)]\n",
    "    new_data_matrix = tf_idf_matrix[len(df_input):]\n",
    "    \n",
    "    #Performing the Perceptron algorithm on the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(orig_data_matrix, df_output, random_state=42)\n",
    "    model = Perceptron()\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test,y_test)\n",
    "    print('The Perceptron algorithm model accuracy: ' +str(accuracy))\n",
    "    \n",
    "    prediction = model.predict(new_data_matrix)\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top news story on the BBC\n",
    "bbc_news_article = '''The furlough scheme will be extended until the end of September by the chancellor in the Budget later.\n",
    "Rishi Sunak said the scheme - which pays 80% of employees' wages for the hours they cannot work in the pandemic - would help millions through \"the challenging months ahead\".\n",
    "Some 600,000 more self-employed people will also be eligible for government help as access to grants is widened.\n",
    "But Labour said the support schemes should have been extended \"months ago\".\n",
    "Mr Sunak will outline a three-point plan to support people through the coming months, rebuild the economy and \"fix\" the public finances in the wake of the pandemic when he delivers his statement to the Commons at about 12:30 GMT.\n",
    "But he has warned of tough economic times ahead and there are reports that he plans to raise some taxes.'''\n",
    "\n",
    "# Here's a fake news article from the New York Mag\n",
    "fake_article = '''Twelve days out from judgment day in an election in which he continues to trail badly, President Trump continues to hammer home an issue that will surely resonate with that small slice of still-undecided voters: his supposedly unfair treatment at the hands of CBS’s Lesley Stahl. After two days of promising to release unedited footage of an as-yet-unaired 60 Minutes interview, during which he walked out prematurely because he was upset with Stahl’s line of questioning, the president finally followed through on Thursday. Throughout the interview, Stahl presses Trump on issues from health care (the president says he hopes the Supreme Court strikes down Obamacare, a politically toxic position) to his derogatory comments about Anthony Fauci (Trump claims he was misinterpreted) to his false claims that the Obama campaign spied on him. The tone is of an adversarial back-and-forth, well within normal journalistic bounds. Nevertheless, Trump continuously claims that Joe Biden hasn’t been given similar treatment by CBS and cuts the proceedings short.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Perceptron algorithm model accuracy: 0.9292929292929293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [bbc_news_article,fake_article]\n",
    "perceptron_classifier(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our Perceptron algorithm has correctly classified both the real and fake news article!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try and improve our model's peformance using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf_idf_matrix\n",
    "y = df_output.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vary the learning rate and see how this affects our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron()\n",
    "#alpha is the learning rate of our Perceptron ALgorithm model\n",
    "param_grid = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x000002811CAC6AC8>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
       "                                  early_stopping=False, eta0=1.0,\n",
       "                                  fit_intercept=True, max_iter=1000,\n",
       "                                  n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "                                  random_state=0, shuffle=True, tol=0.001,\n",
       "                                  validation_fraction=0.1, verbose=0,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "results = grid.fit(x_train, y_train)\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.925 with: {'alpha': 0.0001}\n",
      ">0.925 with: {'alpha': 0.001}\n",
      ">0.925 with: {'alpha': 0.01}\n",
      ">0.925 with: {'alpha': 0.1}\n",
      ">0.925 with: {'alpha': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can see that with all of these learning rates, our Perceptron Algorithm model has a good perfomance with an accuracy of larger than 92.5%.\n",
    "\n",
    "Now we will test whether changing the constant in which the updates are multiplied will improve the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"eta0\": [0.0001, 0.001, 0.01, 0.1, 1.0],}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "results = grid.fit(x_train, y_train)\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.925 with: {'eta0': 0.0001}\n",
      ">0.925 with: {'eta0': 0.001}\n",
      ">0.925 with: {'eta0': 0.01}\n",
      ">0.925 with: {'eta0': 0.1}\n",
      ">0.925 with: {'eta0': 1.0}\n"
     ]
    }
   ],
   "source": [
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that with these different constants, the model still has an accuracy of larger than 92.5%.\n",
    "\n",
    "We can also vary the proportion of data set aside for validation set for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.925 with: {'validation_fraction': 0.001}\n",
      ">0.925 with: {'validation_fraction': 0.002}\n",
      ">0.925 with: {'validation_fraction': 0.01}\n",
      ">0.925 with: {'validation_fraction': 0.02}\n",
      ">0.925 with: {'validation_fraction': 0.1}\n",
      ">0.925 with: {'validation_fraction': 0.2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"validation_fraction\": [0.001, 0.002, 0.01, 0.02, 0.1, 0.2],}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "results = grid.fit(x_train, y_train)\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the validation fractions listed do not affect the accuracy of our Perceptron model.\n",
    "\n",
    "We can also alter the random state of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.925 with: {'random_state': 0}\n",
      ">0.925 with: {'random_state': 1}\n",
      ">0.922 with: {'random_state': 5}\n",
      ">0.923 with: {'random_state': 25}\n",
      ">0.924 with: {'random_state': 42}\n",
      ">0.923 with: {'random_state': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"random_state\": [0, 1, 5, 25, 42, 50],}\n",
    "grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "results = grid.fit(x_train, y_train)\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our model has greatest accuracy with a low random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
