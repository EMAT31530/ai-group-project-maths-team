{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting ensembles are a way of correcting the mistakes of models before them in a sequence of models. I am going to be using a library called CatBoost to implement boosting with our chosen data set. Firstly, I will need to install CatBoost in order to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf_matrix, df_output, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/miniconda3/lib/python3.8/site-packages (0.25)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: graphviz in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: plotly in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.20.2)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (3.4.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/miniconda3/lib/python3.8/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/miniconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/miniconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/miniconda3/lib/python3.8/site-packages (7.6.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (5.5.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (5.1.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/miniconda3/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/miniconda3/lib/python3.8/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/miniconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: appnope; platform_system == \"Darwin\" in /opt/miniconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client in /opt/miniconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: jupyter-core in /opt/miniconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/miniconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: backcall in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (50.3.0.post20201006)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/miniconda3/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/miniconda3/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/miniconda3/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/miniconda3/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/miniconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/miniconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/miniconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/miniconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: nbconvert in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/miniconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: testpath in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: bleach in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/miniconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/miniconda3/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/miniconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.3)\n",
      "Requirement already satisfied: async-generator in /opt/miniconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/miniconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/miniconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/miniconda3/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import six as si\n",
    "!pip install catboost\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6330</td>\n",
       "      <td>4490</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6331</td>\n",
       "      <td>8062</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6332</td>\n",
       "      <td>8622</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6333</td>\n",
       "      <td>4021</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6334</td>\n",
       "      <td>4330</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "...          ...                                                ...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('news.csv')\n",
    "df.head(6335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x80967 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1762247 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('news.csv')\n",
    "df['news'] = df['title'] + ' ' + df['text']\n",
    "convert_to_binary = {'REAL':1,'FAKE':0}\n",
    "df['label'] = df['label'].map(convert_to_binary)\n",
    "df = df.drop([df.columns[0],df.columns[1],df.columns[2]],axis=1)\n",
    "df = df.reindex(columns=['news','label'])\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    filtered_article = ''\n",
    "    article = row['news']\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    df.loc[index, 'news'] = filtered_article\n",
    "    \n",
    "df.head()\n",
    "\n",
    "\n",
    "# We need the Vectorization\n",
    "\n",
    "df_input = df['news']\n",
    "df_output = df['label']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(df_input)\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the training data into both a training data set and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(tf_idf_matrix,df_output,train_size=0.75,random_state=42)\n",
    "x_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/miniconda3/lib/python3.8/site-packages (0.25)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.0.1)\n",
      "Requirement already satisfied: plotly in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.20.2)\n",
      "Requirement already satisfied: graphviz in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.8/site-packages (from catboost) (3.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/miniconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/miniconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/miniconda3/lib/python3.8/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8ecb2c0b8e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install catboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(custom_loss =['Accuracy'],random_seed=42,logging_level='Silent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Boosting classifier from Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides using Catboost, there are boosting classifiers within Scikit learn. There are two that I am going to explore: AdaBoost and the Gradient Boosting Classifier. It will be interesting to see the difference between the accuracy of the CatBoostClassifier and the classifiers from Scikit Learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ABC = AdaBoostClassifier()\n",
    "ABC.fit(x_train,y_train)\n",
    "Accuracy = ABC.score(x_test,y_test)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8974175035868006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(x_train,y_train)\n",
    "accuracy = GBC.score(x_test,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost gives us an accuracy of 86% which is a significantly higher accuracy than that of the Decision tree classifier. GradientBoostingClassifier gives us a 90% accuracy which is extremely high! I now want to test both of these classifiers on unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['the','it','in'])\n",
    "WNL = WordNetLemmatizer()\n",
    "    \n",
    "\n",
    "def article_preprocessor (article):\n",
    "    filtered_article = ''\n",
    "    article = re.sub(r'[^\\w\\s]', '', article)\n",
    "    words = [word.lower() for word in nltk.word_tokenize(article)]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    words_lemmatized = []\n",
    "    for word in words:\n",
    "        if word == 'us':\n",
    "            words_lemmatized.append(word)\n",
    "        else:\n",
    "            words_lemmatized.append(WNL.lemmatize(word))\n",
    "    filtered_article = \" \".join([word for word in words_lemmatized])\n",
    "    return filtered_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_classifier (list_of_articles):\n",
    "    \n",
    "    # Pre-process the articles\n",
    "    articles_pp = [article_preprocessor(article) for article in list_of_articles]\n",
    "    new_input = df_input.append(pd.Series(articles_pp))\n",
    "    tf_idf_matrix = vectorizer.fit_transform(new_input)\n",
    "    orig_data_matrix = tf_idf_matrix[:len(df_input)]\n",
    "    new_data_matrix = tf_idf_matrix[len(df_input):]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(orig_data_matrix, df_output, random_state=42)\n",
    "    ABC = AdaBoostClassifier()\n",
    "    ABC.fit(x_train, y_train)\n",
    "    accuracy = ABC.score(x_test,y_test)\n",
    "    print('AdaBoost accuracy: ' + str(accuracy))\n",
    "    predictions = ABC.predict(new_data_matrix)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def GradientBoost_classifier (list_of_articles):\n",
    "    \n",
    "    # Pre-process the articles\n",
    "    articles_pp = [article_preprocessor(article) for article in list_of_articles]\n",
    "    new_input = df_input.append(pd.Series(articles_pp))\n",
    "    tf_idf_matrix = vectorizer.fit_transform(new_input)\n",
    "    orig_data_matrix = tf_idf_matrix[:len(df_input)]\n",
    "    new_data_matrix = tf_idf_matrix[len(df_input):]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(orig_data_matrix, df_output, random_state=42)\n",
    "    GBC = GradientBoostingClassifier()\n",
    "    GBC.fit(x_train, y_train)\n",
    "    accuracy = GBC.score(x_test,y_test)\n",
    "    print('Gradient Boosting accuracy: ' + str(accuracy))\n",
    "    # The model can now classify the new data\n",
    "    predictions = GBC.predict(new_data_matrix)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top news story on the BBC\n",
    "bbc_news_article = '''The furlough scheme will be extended until the end of September by the chancellor in the Budget later.\n",
    "Rishi Sunak said the scheme - which pays 80% of employees' wages for the hours they cannot work in the pandemic - would help millions through \"the challenging months ahead\".\n",
    "Some 600,000 more self-employed people will also be eligible for government help as access to grants is widened.\n",
    "But Labour said the support schemes should have been extended \"months ago\".\n",
    "Mr Sunak will outline a three-point plan to support people through the coming months, rebuild the economy and \"fix\" the public finances in the wake of the pandemic when he delivers his statement to the Commons at about 12:30 GMT.\n",
    "But he has warned of tough economic times ahead and there are reports that he plans to raise some taxes.'''\n",
    "\n",
    "# Here's a fake news article from the New York Mag\n",
    "fake_article = '''Twelve days out from judgment day in an election in which he continues to trail badly, President Trump continues to hammer home an issue that will surely resonate with that small slice of still-undecided voters: his supposedly unfair treatment at the hands of CBS’s Lesley Stahl. After two days of promising to release unedited footage of an as-yet-unaired 60 Minutes interview, during which he walked out prematurely because he was upset with Stahl’s line of questioning, the president finally followed through on Thursday. Throughout the interview, Stahl presses Trump on issues from health care (the president says he hopes the Supreme Court strikes down Obamacare, a politically toxic position) to his derogatory comments about Anthony Fauci (Trump claims he was misinterpreted) to his false claims that the Obama campaign spied on him. The tone is of an adversarial back-and-forth, well within normal journalistic bounds. Nevertheless, Trump continuously claims that Joe Biden hasn’t been given similar treatment by CBS and cuts the proceedings short.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy: 0.8832070707070707\n",
      "[1 0]\n",
      "Gradient Boosting accuracy: 0.8958333333333334\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "articles = [bbc_news_article,fake_article]\n",
    "print(AdaBoost_classifier(articles))\n",
    "print(GradientBoost_classifier(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with an accuracy of 88%, the Adaboost classifier has correctly identified the real and fake news article. Again, with the Gradient Boost classifier both articles were correctly identified as real or fake with an accuracy of 90%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
